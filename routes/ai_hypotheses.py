# routes/ai_hypotheses.py
from fastapi import APIRouter, HTTPException
from supabase import create_client, Client
from openai import OpenAI
import os
import uuid
import traceback
import json

# --------------------------------------------------------------------
# üß† Initialization
# --------------------------------------------------------------------
router = APIRouter()

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    raise RuntimeError("‚ùå Missing Supabase environment variables.")
if not OPENAI_API_KEY:
    raise RuntimeError("‚ùå Missing OpenAI API key.")

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
openai = OpenAI(api_key=OPENAI_API_KEY)

# --------------------------------------------------------------------
# üöÄ Combined Hypotheses Endpoint
# --------------------------------------------------------------------


@router.get("/hypotheses")
async def get_ai_hypotheses():
    """
    Returns both:
      1. Seeded hypotheses stored in Supabase (ai_hypotheses table)
      2. Live AI-generated hypotheses derived from paper_summaries
    """
    try:
        print("DEBUG: /ai/hypotheses endpoint hit ‚úÖ")
        print("DEBUG: Supabase URL =", SUPABASE_URL)
        print("DEBUG: Keys loaded:", bool(SUPABASE_KEY), bool(OPENAI_API_KEY))

        # 1Ô∏è‚É£ Pull seeded hypotheses
        seeded = (
            supabase.table("ai_hypotheses")
            .select("*")
            .order("created_at", desc=True)
            .execute()
            .data
        ) or []
        print(f"DEBUG: Retrieved {len(seeded)} seeded hypotheses.")

        # 2Ô∏è‚É£ Gather recent paper summaries
        summaries = (
            supabase.table("paper_summaries")
            .select("one_sentence")
            .limit(40)
            .execute()
            .data
        ) or []
        print(f"DEBUG: Retrieved {len(summaries)} paper summaries.")
        if not summaries:
            return seeded

        text_corpus = "\n".join(f"- {s['one_sentence']}" for s in summaries)

        # ----------------------------------------------------------------
        # 3Ô∏è‚É£ Ask GPT for new causal hypotheses (universal compatibility)
        # ----------------------------------------------------------------
        prompt = f"""
        You are a biomedical research AI specializing in ME/CFS.
        Review the following study summaries and propose 3 new causal hypotheses
        linking biological mechanisms and biomarkers.

        Each hypothesis must be valid JSON with fields:
        - title (string)
        - summary (string)
        - confidence (float 0‚Äì1)
        - mechanisms (array of strings)
        - biomarkers (array of strings)
        - citations (array of short strings)

        Return a JSON array (not text).

        Summaries:
        {text_corpus}
        """

        print("DEBUG: Sending prompt to OpenAI...")

        ai_generated = []
        try:
            completion = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
            )
            content = completion.choices[0].message.content.strip()
            print("DEBUG: Raw OpenAI output (first 200 chars):", content[:200])

            # Try to parse as JSON
            if content.startswith("{"):
                ai_generated = [json.loads(content)]
            elif content.startswith("["):
                ai_generated = json.loads(content)
            else:
                start = content.find("[")
                end = content.rfind("]")
                if start != -1 and end != -1:
                    ai_generated = json.loads(content[start:end+1])

        except Exception as e:
            print("ERROR during OpenAI generation:", str(e))
            ai_generated = []

        # ----------------------------------------------------------------
        # 4Ô∏è‚É£ Normalize data + attach UUIDs
        # ----------------------------------------------------------------
        for h in ai_generated:
            h["id"] = str(uuid.uuid4())
            try:
                h["confidence"] = max(
                    0, min(1, float(h.get("confidence", 0.5))))
            except Exception:
                h["confidence"] = 0.5

        print(f"DEBUG: {len(ai_generated)} new hypotheses generated by AI.")

        # ----------------------------------------------------------------
        # 5Ô∏è‚É£ Merge both datasets
        # ----------------------------------------------------------------
        combined = seeded + ai_generated
        print(f"DEBUG: Returning total of {len(combined)} hypotheses.")
        return combined

    except Exception as e:
        print("\n" + "=" * 80)
        print("üî• ERROR in /ai/hypotheses:")
        print(traceback.format_exc())
        print("=" * 80 + "\n")
        raise HTTPException(
            status_code=500, detail=f"Error generating hypotheses: {e}")
